import cv2
import numpy as np
import time
import argparse
import pyorbbecsdk
from pyorbbecsdk import Pipeline, Config, OBSensorType, OBAlignMode, FrameSet
from ultralytics import YOLO
from utils import frame_to_bgr_image

pipeline = Pipeline()
device = pipeline.get_device()
device_info = device.get_device_info()
device_pid = device_info.get_pid()
config = Config()

color_profile = pipeline.get_stream_profile_list(OBSensorType.COLOR_SENSOR).get_default_video_stream_profile()
config.enable_stream(color_profile)


print(f"Color profile: {color_profile.get_width()}x{color_profile.get_height()} @ {color_profile.get_fps()} FPS")

config.set_align_mode(OBAlignMode.HW_MODE)
pipeline.enable_frame_sync()
pipeline.start(config)

time.sleep(2)

model = YOLO("weights/bestn_rknn_model/bestn_rknn_model")  #bestn (nano) –∏–ª–∏ best (small)

TRIGGER_GESTURE = "jumbo"
RESET_GESTURE = "heart"
tracked_hand = None
tracked_trajectory = []
last_inference_time = 0  # –¢–∞–π–º–µ—Ä –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ 1 –∫–∞–¥—Ä –≤ —Å–µ–∫—É–Ω–¥—É
max_miss_frames = 60  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å–±—Ä–æ—Å–∞ —Ç—Ä–µ–∫–∞
missed_frames = 0  # –°—á—ë—Ç—á–∏–∫ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
last_tracked_bbox = None  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –±–æ–∫—Å —Ä—É–∫–∏
last_tracked_trajectory = []  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è –¥–≤–∏–∂–µ–Ω–∏—è


def detect_and_track(color_frame):
    global tracked_hand, tracked_trajectory, last_inference_time, missed_frames, last_tracked_bbox, last_tracked_trajectory

    current_time = time.time()
    if current_time - last_inference_time >= 5:  # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É
        last_inference_time = current_time
        results = model(cv2.resize(color_frame, (640, 640)))

        hands = []
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                label = model.names[int(box.cls)]
                conf = float(box.conf)

                hands.append({
                    "bbox": (x1, y1, x2, y2),
                    "label": label,
                    "confidence": conf
                })

        if tracked_hand is None:
            for hand in hands:
                if hand["label"] == TRIGGER_GESTURE:
                    x1, y1, x2, y2 = hand["bbox"]
                    tracked_hand = {"bbox": hand["bbox"]}
                    tracked_trajectory = []
                    missed_frames = 0
                    last_tracked_bbox = hand["bbox"]  # –ö—ç—à–∏—Ä—É–µ–º –±–æ–∫—Å
                    last_tracked_trajectory = []  # –û—á–∏—â–∞–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
                    print(
                        f"‚úÖ –ó–∞—Ö–≤–∞—á–µ–Ω–∞ —Ä—É–∫–∞ —Å –∂–µ—Å—Ç–æ–º {TRIGGER_GESTURE} - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {x1, y1, x2, y2}")
                    break
        else:
            # –ü–æ–∏—Å–∫ —Å–∞–º–æ–π –±–ª–∏–∑–∫–æ–π —Ä—É–∫–∏ –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –≥–ª—É–±–∏–Ω–µ
            closest_hand = None
            for hand in hands:
                x1, y1, x2, y2 = hand["bbox"]
                closest_hand = hand

            if closest_hand["label"] != RESET_GESTURE:
                tracked_hand["bbox"] = closest_hand["bbox"]
                x1, y1, x2, y2 = tracked_hand["bbox"]
                tracked_trajectory.append(((x1 + x2) // 2, (y1 + y2) // 2))
                missed_frames = 0

                last_tracked_bbox = tracked_hand["bbox"]  # –ö—ç—à–∏—Ä—É–µ–º –±–æ–∫—Å
                last_tracked_trajectory = tracked_trajectory  # –ö—ç—à–∏—Ä—É–µ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é

                print(f"üîµ –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ä—É–∫—É - –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {x1, y1, x2, y2}")
                '''
                –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –ø—Ä–æ–ø–∏—Å–∞—Ç—å –∫–µ–π—Å—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤
                '''

            else:
                missed_frames += 1
                if missed_frames > max_miss_frames or closest_hand["label"] != RESET_GESTURE:
                    print("‚ùå –†—É–∫–∞ –ø–æ—Ç–µ—Ä—è–Ω–∞, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç—Ä–µ–∫")
                    tracked_hand = None
                    tracked_trajectory = []
                    last_tracked_bbox = None
                    last_tracked_trajectory = []

    if last_tracked_bbox:
        x1, y1, x2, y2 = last_tracked_bbox
        cv2.rectangle(color_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(color_frame, "Tracking", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    for i in range(1, len(last_tracked_trajectory)):
        cv2.line(color_frame, last_tracked_trajectory[i - 1], last_tracked_trajectory[i], (0, 0, 255), 2)

    return color_frame


def get_frames():
    print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –æ—Ç –∫–∞–º–µ—Ä—ã...")
    frames: FrameSet = pipeline.wait_for_frames(300)
    print("‚úÖ –ö–∞–¥—Ä—ã –ø–æ–ª—É—á–µ–Ω—ã!")
    if frames is None:
        return None, None

    color_frame = frames.get_color_frame()
    if color_frame is None:
        return None, None
    color_image = frame_to_bgr_image(color_frame)

    return color_image


while True:
    print("‚è≥ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–∞–¥—Ä—ã...")
    color_frame = get_frames()
    print("‚úÖ –ö–∞–¥—Ä—ã –ø–æ–ª—É—á–µ–Ω—ã!")

    if color_frame is None:
        print("‚ö†Ô∏è –ö–∞–¥—Ä—ã –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ...")
        continue

    processed_frame = detect_and_track(color_frame)

    cv2.imshow('Sign Recognition', processed_frame)
    #cv2.waitKey(100)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        pipeline.stop()
        cv2.destroyAllWindows()
        break

pipeline.stop()
cv2.destroyAllWindows()
